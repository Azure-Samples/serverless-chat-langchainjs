{
  "$schema": "https://aka.ms/codetour-schema",
  "title": "3 - Vector Storage: Cosmos DB & FAISS Deep Dive",
  "description": "Understand how vector databases work, similarity metrics, indexing strategies, and when to use Cosmos DB vs FAISS.",
  "nextTour": "4 - Query & Retrieval: Finding Relevant Context",
  "steps": [
    {
      "title": "Vector Storage Deep Dive",
      "description": "## Welcome to Tour 3: Vector Storage! üíæ\n\n### What We'll Explore:\n1. How vector databases work under the hood\n2. Similarity metrics and distance calculations\n3. Azure Cosmos DB vector search capabilities\n4. FAISS indexing algorithms\n5. Storage optimization and scaling\n\n### Why Vector Storage Matters:\n\n**The Challenge:**\n- Millions of document chunks\n- Each chunk = 768-1536 dimensional vector\n- Need to find top-K similar vectors in milliseconds\n\n**The Solution:**\n- Specialized vector databases\n- Smart indexing algorithms\n- Approximate nearest neighbor search\n\n---\n\n### üí° Beginner: The Library Analogy\n\nRegular Database = Library with card catalog (search by title, author)\nVector Database = Library where books are arranged by topic similarity\n- Books about dogs near each other\n- Fiction far from non-fiction\n- You can browse by similarity, not just exact matches!\n\n### üî¨ Advanced Preview:\nWe'll cover:\n- Cosine similarity vs Euclidean distance\n- HNSW, IVF, and flat index trade-offs\n- Cosmos DB's DiskANN implementation\n- Memory vs accuracy vs speed triangles\n\n---\n**Let's dive in!**"
    },
    {
      "file": "packages/api/src/functions/chats-post.ts",
      "line": 62,
      "title": "Initializing Vector Stores",
      "description": "## Connecting to Vector Storage üîå\n\nBoth Azure and local paths create a vector store connection:\n\n### Azure Path:\n```typescript\nconst embeddings = new AzureOpenAIEmbeddings({ azureADTokenProvider });\nconst store = new AzureCosmosDBNoSQLVectorStore(\n  embeddings, \n  { credentials }\n);\n```\n\n### Local Path:\n```typescript\nconst embeddings = new OllamaEmbeddings({ \n  model: ollamaEmbeddingsModel \n});\nconst store = await FaissStore.load(\n  faissStoreFolder, \n  embeddings\n);\n```\n\n### Key Observation:\nBoth return a `VectorStore` object with the same interface:\n- `.asRetriever()` - Create retriever\n- `.similaritySearch()` - Find similar docs\n- `.addDocuments()` - Add new docs\n\n### Why This Matters:\n**Abstraction** = You can swap vector stores without changing retrieval logic!\n\n```typescript\n// This line works with ANY vector store:\nconst retriever = store.asRetriever(3);\n```\n\n---\n\n### üí° Beginner: Interface Consistency\nLike how any USB device works in any USB port, any LangChain vector store works with the same code!\n\n### üî¨ Advanced: The VectorStore Interface\n\nLangChain's `VectorStore` base class enforces:\n```typescript\nabstract class VectorStore {\n  abstract addDocuments(docs): Promise<void>;\n  abstract similaritySearch(query, k): Promise<Document[]>;\n  abstract similaritySearchWithScore(query, k): Promise<[Document, number][]>;\n  // ... more methods\n}\n```\n\nThis enables:\n- Easy A/B testing of vector stores\n- Migration between providers\n- Local dev ‚Üí production deployment\n\n---\n**Next**: How does Cosmos DB store vectors?"
    },
    {
      "file": "infra/core/database/cosmos/sql/cosmos-sql-role-def.bicep",
      "line": 1,
      "title": "Cosmos DB Infrastructure",
      "description": "## Cosmos DB Setup (Infrastructure) ‚òÅÔ∏è\n\nThis Bicep template defines permissions for Cosmos DB access.\n\n### What's Being Created:\n1. **Custom role definition** with permissions:\n   - Read/write documents\n   - Execute queries\n   - Manage containers\n\n2. **Vector search capabilities** (configured elsewhere):\n   - Native vector indexing\n   - Cosine similarity search\n   - Automatic index updates\n\n### Cosmos DB for NoSQL with Vector Search:\n\n**Key Features:**\n- **Hybrid storage**: JSON documents + vector embeddings\n- **Single query**: Filter by metadata AND vector similarity\n- **Global distribution**: Replicate worldwide\n- **Automatic indexing**: Vectors indexed on insert\n\n### Example Document Structure:\n```json\n{\n  \"id\": \"chunk-123\",\n  \"text\": \"The tenant must provide 30 days notice...\",\n  \"embedding\": [0.234, -0.456, ...],  // 1536 floats\n  \"metadata\": {\n    \"source\": \"terms.pdf\",\n    \"page\": 3,\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n```\n\n### Query Example:\n```sql\nSELECT TOP 3 c.text, c.metadata\nFROM c\nWHERE VectorDistance(c.embedding, @queryVector) < 0.8\nORDER BY VectorDistance(c.embedding, @queryVector)\n```\n\n---\n\n### üí° Beginner: Why NoSQL for Vectors?\n\n**NoSQL Benefits:**\n- Flexible schema (any metadata)\n- JSON documents (easy to work with)\n- Built-in vector search (no joins needed)\n\n**vs SQL:**\n- Rigid schemas\n- No native vector support (need extensions)\n\n### üî¨ Advanced: Cosmos DB Vector Indexing\n\n**DiskANN Algorithm**:\n1. Builds graph structure of vectors\n2. Navigation via greedy search\n3. ~95% recall with <10ms latency\n\n**Index Configuration:**\n```json\n{\n  \"indexingPolicy\": {\n    \"vectorIndexes\": [{\n      \"path\": \"/embedding\",\n      \"type\": \"diskANN\",\n      \"quantization\": \"scalar\"\n    }]\n  }\n}\n```\n\n**Trade-offs:**\n- **Quantization**: Reduces storage 4x, minimal accuracy loss\n- **Graph depth**: More edges = faster search, more storage\n- **Build time**: 1M vectors ~ 5-10 minutes\n\n---\n**Next**: Compare with FAISS!"
    },
    {
      "file": "packages/api/src/constants.ts",
      "line": 1,
      "title": "FAISS Configuration",
      "description": "## FAISS Storage Configuration üìÅ\n\nThese constants define where FAISS stores its index:\n\n```typescript\nexport const ollamaChatModel = 'llama3.1:latest';\nexport const ollamaEmbeddingsModel = 'nomic-embed-text:latest';\nexport const faissStoreFolder = './.data';\n```\n\n### FAISS File Structure:\n```\n./.data/\n  ‚îú‚îÄ‚îÄ faiss.index       # Binary index file (vectors + graph)\n  ‚îî‚îÄ‚îÄ docstore.json     # Document store (text + metadata)\n```\n\n### What's in Each File:\n\n**faiss.index** (~40MB for 10K docs):\n- Vector data (compressed)\n- Index structure (graph/tree)\n- Distance metric config\n\n**docstore.json** (~15MB for 10K docs):\n```json\n{\n  \"chunk-123\": {\n    \"pageContent\": \"The tenant must...\",\n    \"metadata\": { \"source\": \"terms.pdf\" }\n  }\n}\n```\n\n### Loading Process:\n```typescript\nconst store = await FaissStore.load(faissStoreFolder, embeddings);\n```\n\n**What happens:**\n1. Read `faiss.index` ‚Üí Load into memory\n2. Read `docstore.json` ‚Üí Parse JSON\n3. Initialize search structures\n4. Ready to query!\n\n**Time:** ~100-500ms for 10K vectors\n**Memory:** ~50-100MB\n\n---\n\n### üí° Beginner: Why Two Files?\n\n**Index**: Fast vector search (binary, optimized)\n**Docstore**: Human-readable text (JSON)\n\nSeparation allows:\n- Fast vector search without loading all text\n- Text retrieval only for matched IDs\n\n### üî¨ Advanced: FAISS Index Types\n\nWe use **IndexFlatL2** (exact search):\n```python\nindex = faiss.IndexFlatL2(768)  # 768 dimensions\n```\n\n**Characteristics:**\n- Brute force: Compare query to EVERY vector\n- Exact results: No approximation\n- Memory: 4 bytes √ó 768 √ó count = 3KB per vector\n- Speed: Linear O(n), but fast for < 100K vectors\n\n**Alternatives:**\n\n**IndexIVFFlat** (faster, approximate):\n- Partition vectors into clusters\n- Search only nearby clusters\n- ~90-95% recall, 10-100x faster\n- Good for 100K-1M vectors\n\n**IndexHNSW** (fastest, approximate):\n- Hierarchical graph structure\n- Navigate from coarse to fine\n- ~99% recall, 100-1000x faster\n- Best for 1M+ vectors\n\n**For local dev**: Flat is perfect‚Äîsimple, exact, fast enough!\n\n---\n**Next**: Understanding similarity metrics!"
    },
    {
      "title": "Similarity Metrics Explained",
      "description": "## How Vector Similarity Works üìê\n\nVector databases measure \"closeness\" between vectors using distance metrics.\n\n### The Three Main Metrics:\n\n#### 1. Cosine Similarity (Most Common for Text)\n```\ncos(Œ∏) = (A ¬∑ B) / (||A|| √ó ||B||)\nRange: -1 (opposite) to 1 (identical)\n```\n\n**What it measures:** Angle between vectors\n\n**Why for text:** Ignores magnitude, focuses on direction\n- \"dog\" and \"dogs\" = very similar angle\n- Document length doesn't matter\n\n**Example:**\n```\nVector A: [1, 2, 3]     (\"puppy\")\nVector B: [2, 4, 6]     (\"dog\")\nCosine = 1.0  ‚Üê Same direction, different magnitude!\n```\n\n---\n\n#### 2. Euclidean Distance (L2)\n```\ndist = sqrt((A1-B1)¬≤ + (A2-B2)¬≤ + ... + (An-Bn)¬≤)\nRange: 0 (identical) to ‚àû (very different)\n```\n\n**What it measures:** Straight-line distance\n\n**When to use:** When magnitude matters\n- Image embeddings\n- Coordinate data\n\n**Example:**\n```\nVector A: [1, 2, 3]\nVector B: [2, 4, 6]\nDistance = 3.74  ‚Üê Farther apart!\n```\n\n---\n\n#### 3. Dot Product\n```\nA ¬∑ B = A1√óB1 + A2√óB2 + ... + An√óBn\nRange: -‚àû to ‚àû\n```\n\n**What it measures:** Projection + magnitude\n\n**When to use:** Pre-normalized vectors\n- Fastest to compute\n- Used in neural networks\n\n---\n\n### üí° Beginner: Visual Intuition\n\nImagine vectors as arrows:\n- **Cosine**: Measures angle (direction)\n- **Euclidean**: Measures distance (length)\n- **Dot Product**: Measures alignment\n\n**For text**: We care about meaning (direction), not word count (length) ‚Üí Use Cosine!\n\n### üî¨ Advanced: Implementation Details\n\n**Azure Cosmos DB**: Cosine similarity (default)\n```sql\nVectorDistance(c.embedding, @query)  -- Returns 0-2 (1 - cosine)\n```\n\n**FAISS**: Can use any metric\n```typescript\n// L2 (Euclidean)\nconst indexL2 = new IndexFlatL2(dimensions);\n\n// Inner Product (Dot Product)\nconst indexIP = new IndexFlatIP(dimensions);\n```\n\n**Conversion between metrics:**\n- Normalized vectors: Cosine ‚âà Dot Product\n- Normalized vectors: Euclidean¬≤ = 2(1 - Cosine)\n\n**Best Practice**: Normalize embeddings, then any metric works similarly!\n\n---\n**Next**: How retrieval uses these metrics!"
    },
    {
      "file": "packages/api/src/functions/chats-post.ts",
      "line": 110,
      "title": "Creating the Retriever",
      "description": "## The Retriever: Configuring Vector Search üîç\n\nThis line is where vector storage meets RAG retrieval:\n\n```typescript\nconst retriever = store.asRetriever(3);\n```\n\n### What `.asRetriever(3)` Does:\n\nCreates a retriever that:\n1. Takes a query (text)\n2. Converts to embedding (via embeddings model)\n3. Searches vector store for top 3 similar vectors\n4. Returns corresponding documents\n\n### Under the Hood:\n\n```typescript\n// Simplified implementation\nasync invoke(query: string): Promise<Document[]> {\n  // 1. Embed the query\n  const queryVector = await embeddings.embedQuery(query);\n  \n  // 2. Search vector store\n  const results = await vectorStore.similaritySearchVectorWithScore(\n    queryVector,\n    3  // top-k\n  );\n  \n  // 3. Return documents (sorted by score)\n  return results.map(([doc, score]) => doc);\n}\n```\n\n### The Number 3:\n\n**Why top-3?**\n- **Too few** (1-2): May miss relevant context\n- **Just right** (3-5): Balanced context without noise\n- **Too many** (10+): Dilutes signal, wastes tokens\n\n**Trade-offs:**\n- More docs = more complete context\n- More docs = more tokens = higher cost\n- More docs = potential noise/confusion\n\n**Our choice**: 3 is sweet spot for most queries\n\n---\n\n### üí° Beginner: Why Not Retrieve All?\n\nImagine searching \"pet policy\":\n- We have 1000 chunks\n- Only 5-10 are relevant\n- LLM can only process ~4000 tokens\n- 3 chunks ‚âà 1500 tokens = perfect fit!\n\n### üî¨ Advanced: Retrieval Strategies\n\n**Beyond Simple Top-K:**\n\n1. **MMR (Maximal Marginal Relevance)**\n```typescript\nconst retriever = store.asRetriever({\n  searchType: 'mmr',\n  searchKwargs: {\n    fetchK: 20,  // Fetch 20\n    lambda: 0.5,  // Diversity parameter\n    k: 3  // Return 3\n  }\n});\n```\n- Balances relevance vs diversity\n- Avoids redundant chunks\n\n2. **Similarity Threshold**\n```typescript\nconst retriever = store.asRetriever({\n  searchType: 'similarity_score_threshold',\n  searchKwargs: {\n    scoreThreshold: 0.8,  // Min score\n    k: 10  // Max results\n  }\n});\n```\n- Only retrieves if score > threshold\n- Variable number of results\n\n3. **Multi-Query Retrieval**\n- Generate multiple versions of query\n- Retrieve for each\n- Combine and deduplicate\n\n**Our Implementation**: Simple top-3 for clarity and reliability!\n\n---\n**Next**: Storage optimization strategies!"
    },
    {
      "title": "Storage Optimization Strategies",
      "description": "## Optimizing Vector Storage üéØ\n\n### The Storage Challenge:\n\n**Example Scale:**\n- 10,000 documents\n- 5 chunks per document = 50,000 chunks\n- 1536 dimensions per vector\n- 4 bytes per dimension (float32)\n\n**Math:**\n```\n50,000 chunks √ó 1536 dims √ó 4 bytes = 307 MB (vectors only!)\n+ metadata + text = ~500 MB total\n```\n\n### Optimization Techniques:\n\n---\n\n#### 1. Quantization\n\n**Reduce precision:**\n- float32 (4 bytes) ‚Üí int8 (1 byte)\n- 75% storage reduction\n- 1-3% accuracy loss\n\n**Example:**\n```\nOriginal:     0.34567891  (4 bytes)\nQuantized:    87          (1 byte, scaled)\n```\n\n**Cosmos DB**: Automatic scalar quantization\n**FAISS**: Manual quantization available\n\n---\n\n#### 2. Dimensionality Reduction\n\n**Reduce dimensions:**\n- 1536 dims ‚Üí 768 dims ‚Üí 384 dims\n- Use PCA or similar techniques\n- 50-75% reduction, 5-10% accuracy loss\n\n**Trade-off:**\n- Less storage\n- Faster search\n- Some semantic information lost\n\n**When to use:** Very large scale (millions of docs)\n\n---\n\n#### 3. Smaller Embedding Models\n\n**Model choices:**\n- text-embedding-3-large: 3072 dims (best quality)\n- text-embedding-3-small: 1536 dims (balanced) ‚Üê We use this\n- nomic-embed-text: 768 dims (good, efficient)\n\n**Halving dimensions = 50% storage savings!**\n\n---\n\n#### 4. Chunk Size Optimization\n\n**Larger chunks:**\n- Fewer total chunks\n- Less storage\n- But: Less precise retrieval\n\n**Example:**\n```\n1000 chars: 100,000 chunks\n1500 chars: 67,000 chunks  ‚Üê 33% fewer!\n2000 chars: 50,000 chunks\n```\n\n---\n\n#### 5. Metadata Pruning\n\n**Only store essential metadata:**\n```typescript\n// Bloated (150 bytes)\n{\n  source: \"terms-of-service.pdf\",\n  uploadedBy: \"user@example.com\",\n  uploadDate: \"2024-01-15T10:30:00Z\",\n  processedBy: \"ingest-v2.3\",\n  originalSize: 1048576,\n  sha256: \"abc123...\"\n}\n\n// Optimized (50 bytes)\n{\n  source: \"terms.pdf\",\n  page: 3\n}\n```\n\n---\n\n### üí° Beginner: The Storage Triangle\n\nPick two:\n- **Accuracy**: High-quality results\n- **Speed**: Fast queries\n- **Storage**: Low cost\n\nYou can't have all three at maximum!\n\n### üî¨ Advanced: Real-World Numbers\n\n**Cosmos DB Serverless Costs:**\n- Storage: $0.25/GB-month\n- 500MB = $0.125/month\n- Request Units dominate cost, not storage!\n\n**FAISS Memory:**\n- 500MB ‚Üí ~600MB in RAM (overhead)\n- Fine for single server\n- Problem at scale: Need distributed solutions\n\n**Optimization Priority:**\n1. **Start simple**: Default settings\n2. **Measure**: Track storage growth\n3. **Optimize**: When cost/performance suffers\n4. **Monitor**: Continuously measure impact\n\n**Premature optimization = wasted time!**\n\n---\n**Next**: When to use which vector store!"
    },
    {
      "title": "Cosmos DB vs FAISS Decision Guide",
      "description": "## Choosing Your Vector Store ü§î\n\n### Quick Decision Tree:\n\n```\nProduction app? ‚Üí YES ‚Üí Cosmos DB\n                ‚Üì NO\n          < 100K vectors? ‚Üí YES ‚Üí FAISS\n                         ‚Üì NO\n                    Multi-user? ‚Üí YES ‚Üí Cosmos DB\n                               ‚Üì NO\n                          Still FAISS (with caveats)\n```\n\n---\n\n## Detailed Comparison:\n\n### Azure Cosmos DB for NoSQL\n\n**‚úÖ Use When:**\n- Production applications\n- Multi-user access\n- Need global distribution\n- Want automatic backups\n- Require high availability (99.99% SLA)\n- Serverless auto-scaling\n\n**‚ùå Don't Use When:**\n- Local development only\n- Trying to minimize costs\n- Learning/experimenting\n- Offline-first requirements\n\n**Costs:**\n- Serverless: $0.28 per 1M RU (request units)\n- Typical: 10 RU per search = $0.0028 per 1K searches\n- Storage: $0.25/GB-month\n- Free tier: 1000 RU/s + 25GB\n\n**Scaling:**\n- 100K to 10M+ vectors: No code changes\n- Automatic index management\n- Global replication available\n\n---\n\n### FAISS (Facebook AI Similarity Search)\n\n**‚úÖ Use When:**\n- Local development\n- Cost-conscious learning\n- Single-machine deployment\n- Batch processing jobs\n- Research/experimentation\n- < 100K vectors\n\n**‚ùå Don't Use When:**\n- Multiple concurrent users\n- Need persistence across restarts\n- Distributed systems\n- Production SLAs required\n\n**Costs:**\n- Free! (open source)\n- Only cost: Compute/memory\n\n**Scaling:**\n- Limited by single machine RAM\n- Must reload from disk on restart\n- Manual index optimization required\n\n---\n\n## Hybrid Approach (Best of Both):\n\n### Development Workflow:\n```\n1. Develop locally with FAISS\n   - Fast iteration\n   - No cloud costs\n   - Full feature testing\n\n2. Test with small Cosmos DB instance\n   - Validate cloud integration\n   - Test deployment scripts\n   - Check performance\n\n3. Deploy to production with Cosmos DB\n   - Same code!\n   - Just environment variables change\n   - Confidence from local testing\n```\n\n### Implementation:\n```typescript\n// Environment-based selection (automatic!)\nconst store = azureOpenAiEndpoint \n  ? new AzureCosmosDBNoSQLVectorStore(...)\n  : await FaissStore.load(...);\n\n// Same interface works for both!\nconst retriever = store.asRetriever(3);\n```\n\n---\n\n### üí° Beginner: Start Local, Go Cloud\n\n**Learning Path:**\n1. Week 1-2: FAISS (understand RAG concepts)\n2. Week 3: Cosmos DB (learn cloud deployment)\n3. Ongoing: Use appropriate tool for each project\n\n**Don't overthink it!** Start with FAISS for learning.\n\n### üî¨ Advanced: Other Vector Database Options\n\n**Managed Services:**\n- **Pinecone**: Vector-only, very fast, pay-per-use\n- **Weaviate**: Open source, GraphQL API, hybrid search\n- **Qdrant**: Rust-based, very fast, open source\n- **Milvus**: Distributed, enterprise-grade, complex\n\n**PostgreSQL Extensions:**\n- **pgvector**: Add vectors to existing Postgres DB\n- **pg_embedding**: Another Postgres option\n\n**Specialized:**\n- **Chroma**: Embedded, Python-focused\n- **LanceDB**: Embedded, serverless\n\n**Why Cosmos DB for this sample:**\n- ‚úÖ Azure-native (matches other services)\n- ‚úÖ Multi-model (documents + vectors)\n- ‚úÖ Serverless (easy to start)\n- ‚úÖ Global distribution (if needed)\n\n---\n**Next**: Tour complete!"
    },
    {
      "title": "Vector Storage Tour Complete! üéâ",
      "description": "## Tour 3 Complete - Vector Storage Mastered! ‚úÖ\n\n### What You've Learned:\n\n#### Core Concepts:\n\n**Beginner Level:**\n‚úÖ Vector databases enable fast similarity search\n‚úÖ Cosine similarity measures semantic closeness\n‚úÖ Top-K retrieval finds most relevant chunks\n‚úÖ FAISS for local, Cosmos DB for production\n\n**Advanced Level:**\n‚úÖ DiskANN indexing algorithm (Cosmos DB)\n‚úÖ IndexFlatL2 vs IVFFLAT vs HNSW (FAISS)\n‚úÖ Quantization for 75% storage reduction\n‚úÖ Retrieval strategies (MMR, thresholds, multi-query)\n‚úÖ Cost-performance trade-offs\n\n---\n\n## üéØ Key Takeaways:\n\n### Storage Comparison:\n| Feature | Cosmos DB | FAISS |\n|---------|-----------|-------|\n| **Best For** | Production | Development |\n| **Scaling** | Millions of vectors | < 100K vectors |\n| **Persistence** | Automatic | Manual (files) |\n| **Cost** | Pay per use | Free |\n| **Setup** | Cloud account | Local install |\n\n### Optimization Priority:\n```\n1. Default settings (start here!)\n2. Measure performance\n3. Optimize if needed\n4. Re-measure impact\n```\n\n**Don't optimize prematurely!**\n\n---\n\n## üöÄ What's Next?\n\nNow that we understand storage, let's see how queries work!\n\n### [Tour 4: Query & Retrieval]\nExplore:\n- Query embedding process\n- Vector similarity search in detail\n- Context ranking and selection\n- Retrieval evaluation metrics\n- Advanced retrieval patterns\n\n---\n\n## üí° Hands-On Ideas:\n\n1. **Compare search quality**:\n   - Try same query with different top-K values\n   - Measure relevance of results\n\n2. **Benchmark performance**:\n   - Time vector search with different index types\n   - Compare FAISS flat vs IVF\n\n3. **Experiment with metrics**:\n   - Change from cosine to euclidean\n   - See how results differ\n\n4. **Monitor costs**:\n   - Check Cosmos DB RU consumption\n   - Calculate cost per 1000 queries\n\n---\n\n### Continue Learning:\n[Tour 4: Query & Retrieval ‚Üí]\n\n---\n\n"
    }
  ]
}
